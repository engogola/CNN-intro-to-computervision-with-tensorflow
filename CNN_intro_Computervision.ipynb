{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN07VH60GKPpHsV6FnzQ/zI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/engogola/CNN-intro-to-computervision-with-tensorflow/blob/main/CNN_intro_Computervision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Download zip file of pizza_steak images\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"pizza_steak.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "3pxsWsbZ3t-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak/train/steak/\n",
        "\n",
        "import os\n",
        "\n",
        "# Walk through pizza_steak directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "# Another way to find out how many images are in a file\n",
        "num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n",
        "\n",
        "num_steak_images_train"
      ],
      "metadata": {
        "id": "40b2bhMbxBhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inspect the data (becoming one with it)\n",
        "A very crucial step at the beginning of any machine learning project is becoming one with data.\n",
        "and for a computer vision project..this usually means visualizing the many samples of your data"
      ],
      "metadata": {
        "id": "hdx31P0o68Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak/train/steak/\n",
        "\n",
        "import os\n",
        "\n",
        "# Walk through pizza_steak directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "# Another way to find out how many images are in a file\n",
        "num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n",
        "\n",
        "num_steak_images_train"
      ],
      "metadata": {
        "id": "31P9Tdgm67iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize our images ,first lets get class names programmatically."
      ],
      "metadata": {
        "id": "vGQJ0C_X1UJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the class names programmatically\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(\"pizza_steak/train/\") # turn our training path into a Python path\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "VzSQrKqM1ShR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets visualise our image\n",
        "# View an image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "  # Setup target directory (we'll view images from here)\n",
        "  target_folder = target_dir+target_class\n",
        "\n",
        "  # Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "\n",
        "  # Read in the image and plot it using matplotlib\n",
        "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\");\n",
        "\n",
        "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
        "\n",
        "  return img\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1lNW8m9d2HNF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View a random image from the training dataset\n",
        "img = view_random_image(target_dir=\"pizza_steak/train/\",\n",
        "                        target_class=\"steak\")"
      ],
      "metadata": {
        "id": "3OmlOOxu3PQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.constant(img)"
      ],
      "metadata": {
        "id": "JjYguzvl3sO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view image shape\n",
        "img.shape #returns width,height,color channels"
      ],
      "metadata": {
        "id": "nE4jVIDh4H1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note;many machine learning models including neural networs prefer the values they work with to be between 0 and 1 i.e dividing the image arrayby 255.\n",
        ""
      ],
      "metadata": {
        "id": "RDuFZfap5HUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the values between 0 and 1 (scale/normalize the data)\n",
        "img/255."
      ],
      "metadata": {
        "id": "sWUJrTWr4sk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An End-to-end Example\n",
        "Lets build a convolution neural network to find patterns in our images,more specifically we need to;\n",
        "*load our images\n",
        "*prepocess our images\n",
        "*Build a CNN to find patterns in our images\n",
        "*Compile our CNN\n",
        "*Fit the CNN to our training Data"
      ],
      "metadata": {
        "id": "MSGrgn-8-CWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup the train and test directories\n",
        "train_dir = \"pizza_steak/train/\"\n",
        "test_dir = \"pizza_steak/test/\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               batch_size=32, # number of images to process at a time\n",
        "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
        "                                               class_mode=\"binary\", # type of problem we're working on\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "# Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=10,\n",
        "                         kernel_size=3, # can also be (3, 3)\n",
        "                         activation=\"relu\",\n",
        "                         input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
        "                            padding=\"valid\"), # padding can also be 'same'\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\") # binary activation output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKQPFVVW6Q1b",
        "outputId": "792a0818-ebad-4bda-b222-1bffc8642f62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1500 images belonging to 2 classes.\n",
            "Found 500 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "47/47 [==============================] - 95s 2s/step - loss: 0.5563 - accuracy: 0.7267 - val_loss: 0.4108 - val_accuracy: 0.8320\n",
            "Epoch 2/5\n",
            "47/47 [==============================] - 97s 2s/step - loss: 0.4572 - accuracy: 0.8000 - val_loss: 0.3949 - val_accuracy: 0.8540\n",
            "Epoch 3/5\n",
            "47/47 [==============================] - 94s 2s/step - loss: 0.4293 - accuracy: 0.8107 - val_loss: 0.3932 - val_accuracy: 0.8380\n",
            "Epoch 4/5\n",
            "47/47 [==============================] - 94s 2s/step - loss: 0.3697 - accuracy: 0.8373 - val_loss: 0.3367 - val_accuracy: 0.8560\n",
            "Epoch 5/5\n",
            "47/47 [==============================] - 96s 2s/step - loss: 0.3020 - accuracy: 0.8767 - val_loss: 0.3804 - val_accuracy: 0.8400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "mwzqjTmb_oqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary classification: Let's break it down\n",
        "We just went through a whirlwind of steps:\n",
        "\n",
        "1.Become one with the data (visualize, visualize, visualize...)\n",
        "2.Preprocess the data (prepare it for a model)\n",
        "3.Create a model (start with a baseline)\n",
        "4.Fit the model\n",
        "5.Evaluate the model\n",
        "6.Adjust different parameters and improve model (try to beat your baseline)\n",
        "7.Repeat until satisfied"
      ],
      "metadata": {
        "id": "Hvt5X4zvBwcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data (requires function 'view_random_image' above)\n",
        "plt.figure()\n",
        "plt.subplot(1, 2, 1)\n",
        "steak_img = view_random_image(\"pizza_steak/train/\", \"steak\")\n",
        "plt.subplot(1, 2, 2)\n",
        "pizza_img = view_random_image(\"pizza_steak/train/\", \"pizza\")"
      ],
      "metadata": {
        "id": "lHVq6cvMBv-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "End-to-end-Multiclass Image Classification.\n",
        "1.Become one with the data\n",
        "2.preprocess the data\n",
        "3.create a model\n",
        "4.fit the model\n",
        "5.Evaluate the model\n",
        "6.Adjust different hyperparameters and improve the model(try to beat the baseline/reduce overfit)\n",
        "8.Repeat until satified."
      ],
      "metadata": {
        "id": "d61thZj-sxiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and become one with the data\n",
        "import zipfile\n",
        "\n",
        "# Download zip file of 10_food_classes images\n",
        "# See how this data was created - https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_all_data.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSHT-kdds8an",
        "outputId": "886eb3e6-4972-4ef2-bb40-53be924c6287"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-08 18:12:21--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.126.207, 74.125.132.207, 74.125.201.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.126.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519183241 (495M) [application/zip]\n",
            "Saving to: ‘10_food_classes_all_data.zip’\n",
            "\n",
            "10_food_classes_all 100%[===================>] 495.13M  51.4MB/s    in 7.6s    \n",
            "\n",
            "2024-05-08 18:12:29 (64.9 MB/s) - ‘10_food_classes_all_data.zip’ saved [519183241/519183241]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through 10_food_classes directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "LqINbtYRs7HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setup the train and test directories\n",
        "train_dir = \"10_food_classes_all_data/train/\"\n",
        "test_dir = \"10_food_classes_all_data/test/\""
      ],
      "metadata": {
        "id": "FSPb90ZMvP-j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets get the class names\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm-52dhevWfk",
        "outputId": "9adee4e4-530b-459f-8d9d-7289aa4b9871"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['chicken_curry' 'chicken_wings' 'fried_rice' 'grilled_salmon' 'hamburger'\n",
            " 'ice_cream' 'pizza' 'ramen' 'steak' 'sushi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View a random image from the training dataset\n",
        "import random\n",
        "img = view_random_image(target_dir=train_dir,\n",
        "                        target_class=random.choice(class_names)) # get a random class name"
      ],
      "metadata": {
        "id": "9xaItc6EWqXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.**Preprocess the data (prepare it for a model)**After going through a handful of images (it's good to visualize at least 10-100 different examples), it looks like our data directories are setup correctly."
      ],
      "metadata": {
        "id": "PWOah5wOYPyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rescale the data and create data generator instances\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Load data in from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical') # changed to categorical\n",
        "\n",
        "test_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')"
      ],
      "metadata": {
        "id": "NbsScZVRYnMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3**. Create a model (start with a baseline)**\n",
        "\n",
        "We can use the same model (TinyVGG) we used for the binary classification problem for our multi-class classification problem with a couple of small tweaks.\n",
        "\n",
        "Namely:\n",
        "\n",
        "1.Changing the output layer to use have 10 ouput neurons (the same number as the number of classes we have).\n",
        "2.Changing the output layer to use 'softmax' activation instead of 'sigmoid' activation.\n",
        "3.Changing the loss function to be 'categorical_crossentropy' instead of 'binary_crossentropy'.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K0WbIeEUb1Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "# Create our model (a clone of model_8, except to be multi-class)\n",
        "model_9 = Sequential([\n",
        "  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax') # changed to have 10 neurons (same as number of classes) and 'softmax' activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_9.compile(loss=\"categorical_crossentropy\", # changed to categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "euFXX1mJcHUr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.** Fit a model**\n",
        "Now we've got a model suited for working with multiple classes, let's fit it to our data."
      ],
      "metadata": {
        "id": "l8zOC3MxegR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_9 = model_9.fit(train_data, # now 10 different classes\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "nLziw5ITejnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATE THE MODEL"
      ],
      "metadata": {
        "id": "HExQDiEq93t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate on the test data\n",
        "model_9.evaluate(test_data)"
      ],
      "metadata": {
        "id": "e-57uYtP93SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the model's loss curves on the 10 classes of data (note: this function comes from above in the notebook)\n",
        "plot_loss_curves(history_9)"
      ],
      "metadata": {
        "id": "pDckQF3_-RRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Woah, that's quite the gap between the training and validation loss curves.\n",
        "\n",
        "What does this tell us?\n",
        "\n",
        "It seems our model is overfitting the training set quite badly. In other words, it's getting great results on the training data but fails to generalize well to unseen data and performs poorly on the test data."
      ],
      "metadata": {
        "id": "3DL7VuAz-VcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Adjust the model parameters\n",
        "Due to its performance on the training data, it's clear our model is learning something. However, performing well on the training data is like going well in the classroom but failing to use your skills in real life.\n",
        "\n",
        "Ideally, we'd like our model to perform as well on the test data as it does on the training data.\n",
        "\n",
        "So our next steps will be to try and prevent our model overfitting. A couple of ways to prevent overfitting include:\n",
        "\n",
        "Get more data - Having more data gives the model more opportunities to learn patterns, patterns which may be more generalizable to new examples.\n",
        "Simplify model - If the current model is already overfitting the training data, it may be too complicated of a model. This means it's learning the patterns of the data too well and isn't able to generalize well to unseen data. One way to simplify a model is to reduce the number of layers it uses or to reduce the number of hidden units in each layer.\n",
        "Use data augmentation - Data augmentation manipulates the training data in a way so that's harder for the model to learn as it artificially adds more variety to the data. If a model is able to learn patterns in augmented data, the model may be able to generalize better to unseen data.\n",
        "Use transfer learning - Transfer learning involves leverages the patterns (also called pretrained weights) one model has learned to use as the foundation for your own task. In our case, we could use one computer vision model pretrained on a large variety of images and then tweak it slightly to be more specialized for food images.\n",
        "🔑 Note: Preventing overfitting is also referred to as regularization.\n",
        "\n",
        "If you've already got an existing dataset, you're probably most likely to try one or a combination of the last three above options first.\n",
        "\n",
        "Since collecting more data would involve us manually taking more images of food, let's try the ones we can do from right within the notebook.\n",
        "\n",
        "How about we simplify our model first?\n",
        "\n",
        "To do so, we'll remove two of the convolutional layers, taking the total number of convolutional layers from four to two.\n",
        "\n"
      ],
      "metadata": {
        "id": "8eg76TDyEQk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mP1Mv40-BViG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try a simplified model (removed two layers)\n",
        "model_10 = Sequential([\n",
        "  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_10.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "history_10 = model_10.fit(train_data,\n",
        "                          epochs=5,\n",
        "                          steps_per_epoch=len(train_data),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "OqX6lO6sD_5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about data augmentation?\n",
        "\n",
        "Data augmentation makes it harder for the model to learn on the training data and in turn, hopefully making the patterns it learns more generalizable to unseen data.\n",
        "\n",
        "To create augmented data, we'll recreate a new ImageDataGenerator instance, this time adding some parameters such as rotation_range and horizontal_flip to manipulate our images."
      ],
      "metadata": {
        "id": "j6eDYcDgElKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create augmented data generator instance\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=20, # note: this is an int not a float\n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                  target_size=(224, 224),\n",
        "                                                                  batch_size=32,\n",
        "                                                                  class_mode='categorical')"
      ],
      "metadata": {
        "id": "ncSoGODGEm97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got augmented data, let's see how it works with the same model as before (model_10).\n",
        "\n",
        "Rather than rewrite the model from scratch, we can clone it using a handy function in TensorFlow called clone_model which can take an existing model and rebuild it in the same format.\n",
        "\n",
        "The cloned version will not include any of the weights (patterns) the original model has learned. So when we train it, it'll be like training a model from scratch."
      ],
      "metadata": {
        "id": "EMMUYB_sFGJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the model (use the same architecture)\n",
        "model_11 = tf.keras.models.clone_model(model_10)\n",
        "\n",
        "# Compile the cloned model (same setup as used for model_10)\n",
        "model_11.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_11 = model_11.fit(train_data_augmented, # use augmented data\n",
        "                          epochs=5,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "ljoNZmKtFIhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model's performance with augmented data\n",
        "plot_loss_curves(history_11)"
      ],
      "metadata": {
        "id": "ncpagCJ2Igc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a prediction with our trained model\n",
        "What good is a model if you can't make predictions with it?\n",
        "\n",
        "Let's first remind ourselves of the classes our multi-class model has been trained on and then we'll download some of own custom images to work with."
      ],
      "metadata": {
        "id": "qoxbItVyIoz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What classes has our model been trained on?\n",
        "class_names"
      ],
      "metadata": {
        "id": "P2eIvzTwIsS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the output of the predict function\n",
        "pred = model_11.predict(tf.expand_dims(img, axis=0))\n",
        "pred"
      ],
      "metadata": {
        "id": "oXmNLRqLIqyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust function to work with multi-class\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "dwYrGjC0JCSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving and loading our model**\n",
        "Once you've trained a model, you probably want to be able to save it and load it somewhere else.\n",
        "\n",
        "To do so, we can use the save and load_model functions."
      ],
      "metadata": {
        "id": "euTp46eHJLdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a model\n",
        "model_11.save(\"saved_trained_model\")"
      ],
      "metadata": {
        "id": "hD68S4jhJTp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in a model and evaluate it\n",
        "loaded_model_11 = tf.keras.models.load_model(\"saved_trained_model\")\n",
        "loaded_model_11.evaluate(test_data)"
      ],
      "metadata": {
        "id": "Mxp4R3apJYPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}